{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Naive Bayes To Differentiate Real from Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing all the libs I think I need\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_status_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>Real_or_Fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.868981e+09</td>\n",
       "      <td>3/22/2016 18:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>7.120000e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.571870e+09</td>\n",
       "      <td>10/10/2016 20:57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clinton: Trump should?ve apologized more, atta...</td>\n",
       "      <td>7.860000e+17</td>\n",
       "      <td>&lt;a href=\"http://twitterfeed.com\" rel=\"nofollow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.710805e+09</td>\n",
       "      <td>2/22/2017 12:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>8.340000e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.584153e+09</td>\n",
       "      <td>12/26/2016 15:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>8.130000e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.768260e+09</td>\n",
       "      <td>8/6/2017 2:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>8.940000e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       user_id         timestamp favorite_count  retweet_count  \\\n",
       "0           0  1.868981e+09   3/22/2016 18:31            NaN            NaN   \n",
       "1           1  2.571870e+09  10/10/2016 20:57              0            0.0   \n",
       "2           2  1.710805e+09   2/22/2017 12:43            NaN            NaN   \n",
       "3           3  2.584153e+09  12/26/2016 15:06            NaN            NaN   \n",
       "4           4  1.768260e+09     8/6/2017 2:36            NaN            NaN   \n",
       "\n",
       "                                                text      tweet_id  \\\n",
       "0  #IslamKills Are you trying to say that there w...  7.120000e+17   \n",
       "1  Clinton: Trump should?ve apologized more, atta...  7.860000e+17   \n",
       "2  RT @ltapoll: Who was/is the best president of ...  8.340000e+17   \n",
       "3  RT @jww372: I don't have to guess your religio...  8.130000e+17   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...  8.940000e+17   \n",
       "\n",
       "                                              source  retweet_status_id  \\\n",
       "0                                                NaN                NaN   \n",
       "1  <a href=\"http://twitterfeed.com\" rel=\"nofollow...                NaN   \n",
       "2                                                NaN                NaN   \n",
       "3                                                NaN                NaN   \n",
       "4                                                NaN                NaN   \n",
       "\n",
       "   in_reply_to_status_id Real_or_Fake  \n",
       "0                    NaN         Fake  \n",
       "1                    NaN         Fake  \n",
       "2                    NaN         Fake  \n",
       "3                    NaN         Fake  \n",
       "4                    NaN         Fake  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This file is scaled-down version of the one I created in the data wrangling module. That file was 2.5GB+ and contained\n",
    "#account information as well. We'll only be working with tweets for this part and this file is only ~250MB.\n",
    "tweets = pd.read_csv('Downloads/ML_Data.csv', encoding='Latin-1', low_memory=False)\n",
    "\n",
    "tweets= tweets[~tweets.text.isnull()]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248047\n",
      "Real    1044586\n",
      "Fake     203461\n",
      "Name: Real_or_Fake, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['Real_or_Fake'].count())\n",
    "print(tweets['Real_or_Fake'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In the next cell, CountVectorizer and HashingVectorizer are both returning memory errors so for the purpose of this exercise\n",
    "#I'm going to size it down some by slicing the data and stick with CountVectorizer. I'll split the data to get as close to 50/50 as I can\n",
    "#MEMErrors: 200000, 100000, 45000, 20000, 10000, 7000,\n",
    "tweets_slice = tweets[200000:206500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Build vocabulary\n",
    "text = tweets_slice['text']\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(text)\n",
    "\n",
    "x = vectorizer.transform(text)\n",
    "x = x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to use the tweet content to determine if it was made by either a bot or a real person, so X should be the tweet and\n",
    "#Y is the indicator\n",
    "def make_xy(tweets, vectorizer=None):   \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer(min_df=0)\n",
    "    X = vectorizer.fit_transform(tweets.text)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = (tweets.Real_or_Fake == 'Real').values.astype(np.int)\n",
    "    return X, y\n",
    "X, y = make_xy(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN Accuracy: 95.81%\n"
     ]
    }
   ],
   "source": [
    "#Now we split the data into train and test sets\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "clf = MultinomialNB().fit(xtrain, ytrain)\n",
    "print(\"MN Accuracy: %0.2f%%\" % (100 * clf.score(xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.97\n",
      "Accuracy on test data:     0.96\n"
     ]
    }
   ],
   "source": [
    "#This cell is important because our if the accuracy on the training data and test data are significantly different, it can\n",
    "#indicate overifitting or underfitting\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "def cv_score(clf, X, y, scorefunc):\n",
    "    result = 0.\n",
    "    nfold = 10 #lets try 10 and see what happens\n",
    "    for train, test in KFold(y.size, nfold): # split data into train/test groups, n times\n",
    "        clf.fit(X[train], y[train]) # fit\n",
    "        result += scorefunc(clf, X[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(clf, x, y):\n",
    "    prob = clf.predict_log_proba(x)\n",
    "    Fake = y == 0\n",
    "    Real = ~Fake\n",
    "    return prob[Fake, 0].sum() + prob[Real, 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(range(tweets.shape[0]), train_size=0.7)\n",
    "mask=np.ones(tweets.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex Buslawski\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1.000000\n",
      "min_df: 0.001000\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "alphas = [0, .1, 1, 5, 10, 50]\n",
    "min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "#Find the best value for alpha and min_df, and the best classifier\n",
    "best_alpha = None\n",
    "best_min_df = None\n",
    "maxscore=-np.inf\n",
    "for alpha in alphas:\n",
    "    for min_df in min_dfs:         \n",
    "        vectorizer = CountVectorizer(min_df = min_df)       \n",
    "        Xthis, ythis = make_xy(tweets, vectorizer)\n",
    "        Xtrainthis=Xthis[mask]\n",
    "        ytrainthis=ythis[mask]\n",
    "        #your code here\n",
    "        clf = MultinomialNB(alpha=alpha)\n",
    "        cvscore = cv_score(clf, Xtrainthis, ytrainthis, log_likelihood)\n",
    "\n",
    "        if cvscore > maxscore:\n",
    "            maxscore = cvscore\n",
    "            best_alpha, best_min_df = alpha, min_df\n",
    "            \n",
    "print(\"alpha: %f\" % best_alpha)\n",
    "print(\"min_df: %f\" % best_min_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
